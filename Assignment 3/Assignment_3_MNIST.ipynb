{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ad9c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 5693\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "NUM_OF_CATEGORY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f735fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.fashion_mnist\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_final_test, y_final_test = x_test, y_test\n",
    "\n",
    "x_test = x_train[50000:60000]\n",
    "x_train = x_train[0:50000]\n",
    "y_test = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]\n",
    "\n",
    "x_train, x_test, x_final_test = np.reshape(x_train / 255.0, (int(tf.shape(x_train)[0]),-1)), np.reshape(x_test / 255.0, (int(tf.shape(x_test)[0]),-1)), np.reshape(x_final_test / 255.0, (int(tf.shape(x_final_test)[0]),-1))\n",
    "one_hot_y = lambda t: [1 if i == t else 0 for i in range(NUM_OF_CATEGORY)]\n",
    "y_train, y_test, y_final_test = np.array([one_hot_y(y) for y in y_train]), np.array([one_hot_y(y) for y in y_test]), np.array([one_hot_y(y) for y in y_final_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fb30ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self, size_input, size_hidden, size_output, device=None):\n",
    "        super(MLP, self).__init__()\n",
    "        \"\"\"\n",
    "        size_input: int, size of input layer\n",
    "        size_hidden: int, size of hidden layer\n",
    "        size_output: int, size of output layer\n",
    "        device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
    "        \"\"\"\n",
    "        self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
    "        size_input, size_hidden, size_output, device\n",
    "\n",
    "        # Initialize weights between input layer and hidden layer 1\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden], seed=seed, stddev=0.1))\n",
    "        # Initialize biases for hidden layer 1\n",
    "        self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden], seed=seed))\n",
    "         # Initialize weights between hidden layer 1 and hidden layer 2\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.size_hidden, self.size_hidden], seed=seed, stddev=0.1))\n",
    "        # Initialize biases for hidden layer 2\n",
    "        self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden], seed=seed))\n",
    "         # Initialize weights between hidden layer 2 and output layer\n",
    "        self.W3 = tf.Variable(tf.random.normal([self.size_hidden, self.size_output], seed=seed, stddev=0.1))\n",
    "        # Initialize biases for output layer\n",
    "        self.b3 = tf.Variable(tf.random.normal([1, self.size_output], seed=seed))\n",
    "\n",
    "        # Define variables to be updated during backpropagation\n",
    "        self.MLP_variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "        # self.MLP_variables = [self.W1, self.W3, self.b1, self.b3]\n",
    "        \n",
    "        # Initialize parameters for Stochastic optimization\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.beta3 = 0.999987\n",
    "        self.epsilon = pow(10,-8)\n",
    "        # Initialize variables for Stochastic optimization\n",
    "        self.t = 0\n",
    "        self.m = []\n",
    "        self.v = []\n",
    "        self.u = []\n",
    "        for var in self.MLP_variables:\n",
    "            self.m.append(tf.Variable(tf.zeros_like(var), trainable=False))\n",
    "            self.v.append(tf.Variable(tf.zeros_like(var), trainable=False))\n",
    "            self.u.append(tf.Variable(tf.zeros_like(var), trainable=False))\n",
    "        \n",
    "    \n",
    "    def forward(self, X, dropout_rate=0):\n",
    "        \"\"\"\n",
    "        forward pass\n",
    "        X: Tensor, inputs\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
    "                self.y = self.compute_output(X, dropout_rate=dropout_rate)\n",
    "        else:\n",
    "            self.y = self.compute_output(X, dropout_rate=dropout_rate)\n",
    "\n",
    "        return self.y\n",
    "  \n",
    "    def loss(self, y_pred, y_true, L1=0, L2=0):\n",
    "        '''\n",
    "        y_pred - Tensor of shape (batch_size, size_output)\n",
    "        y_true - Tensor of shape (batch_size, size_output)\n",
    "        '''\n",
    "        y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        l2_penlty = (tf.nn.l2_loss(self.W1)+tf.nn.l2_loss(self.W2)+tf.nn.l2_loss(self.W3))*L2\n",
    "        loss_with_l2 = l2_penlty+tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
    "#         print(\"y_true_tf\",y_true_tf,\"y_pred_tf\",y_pred_tf)\n",
    "        return loss_with_l2\n",
    "  \n",
    "    def backward(self, X_train, y_train, dropout_rate, learning_rate, L1=0, L2=0):\n",
    "        \"\"\"\n",
    "        backward pass\n",
    "        \"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(X_train,dropout_rate=dropout_rate)\n",
    "            current_loss = self.loss(predicted, y_train, L2=L2)\n",
    "        grads = tape.gradient(current_loss, self.MLP_variables)\n",
    "        \n",
    "        self.t += 1\n",
    "        for i in range(len(self.MLP_variables)):\n",
    "            \n",
    "            self.m[i].assign(self.beta1*self.m[i]+(1-self.beta1)*grads[i])\n",
    "            self.v[i].assign(self.beta2*self.v[i]+(1-self.beta2)*grads[i]*grads[i])\n",
    "            self.u[i].assign(self.beta3*self.u[i]+(1-self.beta3)*grads[i]*grads[i]*grads[i])\n",
    "            \n",
    "            \n",
    "            m_hat = self.m[i]/(1-pow(self.beta1,self.t))\n",
    "            v_hat = self.v[i]/(1-pow(self.beta2,self.t))\n",
    "            u_hat = self.u[i]/(1-pow(self.beta3,self.t))\n",
    "            \n",
    "            update_var = self.MLP_variables[i] - learning_rate*m_hat/(tf.pow(v_hat, 1/2)+tf.sign(u_hat)*tf.pow(tf.abs(u_hat), 1/3)*pow(10,-8)+pow(10,-8))\n",
    "            self.MLP_variables[i].assign(update_var)\n",
    "\n",
    "        return current_loss, predicted\n",
    "        \n",
    "        \n",
    "    def compute_output(self, X, dropout_rate=0):\n",
    "        \"\"\"\n",
    "        Custom method to obtain output tensor during forward pass\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        X_tf = tf.cast(X, dtype=tf.float32)\n",
    "        #Remember to normalize your dataset before moving forward\n",
    "        # Compute values in hidden layer 1\n",
    "        what = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        hhat = tf.nn.relu(what)\n",
    "        # Implement Dropout\n",
    "#         hhat = tf.nn.dropout(hhat, rate = dropout_rate, seed=seed)\n",
    "\n",
    "        # Compute values in hidden layer 2\n",
    "        what = tf.matmul(hhat, self.W2) + self.b2\n",
    "        hhat = tf.nn.relu(what)\n",
    "        # Implement Dropout\n",
    "#         hhat = tf.nn.dropout(hhat, rate = dropout_rate, seed=seed)\n",
    "\n",
    "        # Compute output\n",
    "        output = tf.matmul(hhat, self.W3) + self.b3\n",
    "        #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
    "        #Second add tf.Softmax(output) and then return this variable\n",
    "        return tf.nn.softmax(output)\n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d563dcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.8826740625 - Training Accuracy:= 0.9292600750923157 - Test Accuracy:= 0.936500072479248\n",
      "Time taken (in seconds): 7.19\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.443820546875 - Training Accuracy:= 0.9522000551223755 - Test Accuracy:= 0.9571000337600708\n",
      "Time taken (in seconds): 7.04\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.3504837890625 - Training Accuracy:= 0.9624600410461426 - Test Accuracy:= 0.9647000432014465\n",
      "Time taken (in seconds): 7.11\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.295819609375 - Training Accuracy:= 0.969700038433075 - Test Accuracy:= 0.9679000377655029\n",
      "Time taken (in seconds): 6.56\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.26004109375 - Training Accuracy:= 0.9723200798034668 - Test Accuracy:= 0.9696000218391418\n",
      "Time taken (in seconds): 6.39\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.23482779296875 - Training Accuracy:= 0.9762800931930542 - Test Accuracy:= 0.9700000286102295\n",
      "Time taken (in seconds): 6.48\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.2157773828125 - Training Accuracy:= 0.9786000847816467 - Test Accuracy:= 0.9723000526428223\n",
      "Time taken (in seconds): 6.35\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.2010159375 - Training Accuracy:= 0.9800600409507751 - Test Accuracy:= 0.971500039100647\n",
      "Time taken (in seconds): 6.22\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.1884046484375 - Training Accuracy:= 0.9822400808334351 - Test Accuracy:= 0.9742000699043274\n",
      "Time taken (in seconds): 6.40\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.1811190234375 - Training Accuracy:= 0.9831200838088989 - Test Accuracy:= 0.9750000238418579\n",
      "Time taken (in seconds): 6.43\n",
      "1 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.894633515625 - Training Accuracy:= 0.9320000410079956 - Test Accuracy:= 0.9399000406265259\n",
      "Time taken (in seconds): 6.46\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.458463046875 - Training Accuracy:= 0.9518200755119324 - Test Accuracy:= 0.9554000496864319\n",
      "Time taken (in seconds): 6.39\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.363612890625 - Training Accuracy:= 0.962100088596344 - Test Accuracy:= 0.963100016117096\n",
      "Time taken (in seconds): 6.46\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.3065208984375 - Training Accuracy:= 0.9686200618743896 - Test Accuracy:= 0.9671000242233276\n",
      "Time taken (in seconds): 6.45\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.269133671875 - Training Accuracy:= 0.9709800481796265 - Test Accuracy:= 0.967400074005127\n",
      "Time taken (in seconds): 6.29\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.2410093359375 - Training Accuracy:= 0.9763800501823425 - Test Accuracy:= 0.9707000255584717\n",
      "Time taken (in seconds): 6.50\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.22084595703125 - Training Accuracy:= 0.9777000546455383 - Test Accuracy:= 0.9704000353813171\n",
      "Time taken (in seconds): 6.51\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.2039364453125 - Training Accuracy:= 0.9786200523376465 - Test Accuracy:= 0.9712000489234924\n",
      "Time taken (in seconds): 6.32\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.190755 - Training Accuracy:= 0.9810800552368164 - Test Accuracy:= 0.9737000465393066\n",
      "Time taken (in seconds): 6.40\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.182642265625 - Training Accuracy:= 0.9803200364112854 - Test Accuracy:= 0.9728000164031982\n",
      "Time taken (in seconds): 6.46\n",
      "2 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.89836125 - Training Accuracy:= 0.9297000765800476 - Test Accuracy:= 0.9368000626564026\n",
      "Time taken (in seconds): 6.47\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.463746875 - Training Accuracy:= 0.951240062713623 - Test Accuracy:= 0.955500066280365\n",
      "Time taken (in seconds): 6.36\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.3662925 - Training Accuracy:= 0.9613600373268127 - Test Accuracy:= 0.9639000296592712\n",
      "Time taken (in seconds): 6.46\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.307780625 - Training Accuracy:= 0.969480037689209 - Test Accuracy:= 0.9686000347137451\n",
      "Time taken (in seconds): 6.49\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.26890876953125 - Training Accuracy:= 0.9718600511550903 - Test Accuracy:= 0.969200074672699\n",
      "Time taken (in seconds): 6.33\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.24138955078125 - Training Accuracy:= 0.9772600531578064 - Test Accuracy:= 0.9732000231742859\n",
      "Time taken (in seconds): 6.32\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.2202996484375 - Training Accuracy:= 0.9795400500297546 - Test Accuracy:= 0.9728000164031982\n",
      "Time taken (in seconds): 6.48\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.20386328125 - Training Accuracy:= 0.9800000786781311 - Test Accuracy:= 0.9737000465393066\n",
      "Time taken (in seconds): 6.44\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.19050794921875 - Training Accuracy:= 0.9823600649833679 - Test Accuracy:= 0.9745000600814819\n",
      "Time taken (in seconds): 6.28\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.182486953125 - Training Accuracy:= 0.9836200475692749 - Test Accuracy:= 0.9756000638008118\n",
      "Time taken (in seconds): 6.59\n",
      "3 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.880255 - Training Accuracy:= 0.9295000433921814 - Test Accuracy:= 0.9333000183105469\n",
      "Time taken (in seconds): 6.58\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.4512108984375 - Training Accuracy:= 0.9517200589179993 - Test Accuracy:= 0.9550000429153442\n",
      "Time taken (in seconds): 6.28\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.3568260546875 - Training Accuracy:= 0.9619200825691223 - Test Accuracy:= 0.96260005235672\n",
      "Time taken (in seconds): 6.37\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.3018033203125 - Training Accuracy:= 0.9691800475120544 - Test Accuracy:= 0.9663000702857971\n",
      "Time taken (in seconds): 6.52\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.2658071484375 - Training Accuracy:= 0.9710800647735596 - Test Accuracy:= 0.9668000340461731\n",
      "Time taken (in seconds): 6.35\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.23932166015625 - Training Accuracy:= 0.9759600758552551 - Test Accuracy:= 0.9700000286102295\n",
      "Time taken (in seconds): 6.22\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.21951796875 - Training Accuracy:= 0.9779600501060486 - Test Accuracy:= 0.9712000489234924\n",
      "Time taken (in seconds): 6.46\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.20379439453125 - Training Accuracy:= 0.9798200726509094 - Test Accuracy:= 0.9720000624656677\n",
      "Time taken (in seconds): 6.48\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.190947421875 - Training Accuracy:= 0.9816200733184814 - Test Accuracy:= 0.9724000692367554\n",
      "Time taken (in seconds): 6.40\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.182858828125 - Training Accuracy:= 0.9819600582122803 - Test Accuracy:= 0.9732000231742859\n",
      "Time taken (in seconds): 6.35\n",
      "4 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.8833396875 - Training Accuracy:= 0.9309600591659546 - Test Accuracy:= 0.9356000423431396\n",
      "Time taken (in seconds): 6.54\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.443351015625 - Training Accuracy:= 0.9532800912857056 - Test Accuracy:= 0.9561000466346741\n",
      "Time taken (in seconds): 6.41\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.3495408984375 - Training Accuracy:= 0.96368008852005 - Test Accuracy:= 0.9640000462532043\n",
      "Time taken (in seconds): 6.32\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.2945456640625 - Training Accuracy:= 0.9713000655174255 - Test Accuracy:= 0.9671000242233276\n",
      "Time taken (in seconds): 6.48\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.2584266015625 - Training Accuracy:= 0.9734000563621521 - Test Accuracy:= 0.9691000580787659\n",
      "Time taken (in seconds): 6.48\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.23318837890625 - Training Accuracy:= 0.9773600697517395 - Test Accuracy:= 0.971000075340271\n",
      "Time taken (in seconds): 6.29\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.21353765625 - Training Accuracy:= 0.978640079498291 - Test Accuracy:= 0.9720000624656677\n",
      "Time taken (in seconds): 6.34\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.19903326171875 - Training Accuracy:= 0.9801800847053528 - Test Accuracy:= 0.971000075340271\n",
      "Time taken (in seconds): 6.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epoch = 9 - Training Cross Entropy:= 0.186679140625 - Training Accuracy:= 0.9828600883483887 - Test Accuracy:= 0.973300039768219\n",
      "Time taken (in seconds): 6.47\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.17887765625 - Training Accuracy:= 0.9836800694465637 - Test Accuracy:= 0.9738000631332397\n",
      "Time taken (in seconds): 6.26\n",
      "5 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.94073453125 - Training Accuracy:= 0.9298200607299805 - Test Accuracy:= 0.9363000392913818\n",
      "Time taken (in seconds): 6.45\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.457803671875 - Training Accuracy:= 0.9517200589179993 - Test Accuracy:= 0.955500066280365\n",
      "Time taken (in seconds): 6.50\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.36238421875 - Training Accuracy:= 0.9626200795173645 - Test Accuracy:= 0.9642000198364258\n",
      "Time taken (in seconds): 6.35\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.30627927734375 - Training Accuracy:= 0.9699000716209412 - Test Accuracy:= 0.9688000679016113\n",
      "Time taken (in seconds): 6.33\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.2689073828125 - Training Accuracy:= 0.9727400541305542 - Test Accuracy:= 0.9687000513076782\n",
      "Time taken (in seconds): 6.47\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.24232025390625 - Training Accuracy:= 0.9780800938606262 - Test Accuracy:= 0.9717000722885132\n",
      "Time taken (in seconds): 6.48\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.2206991796875 - Training Accuracy:= 0.9796200394630432 - Test Accuracy:= 0.9719000458717346\n",
      "Time taken (in seconds): 6.28\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.2055074609375 - Training Accuracy:= 0.9800800681114197 - Test Accuracy:= 0.9719000458717346\n",
      "Time taken (in seconds): 6.46\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.1927625 - Training Accuracy:= 0.9828000664710999 - Test Accuracy:= 0.9730000495910645\n",
      "Time taken (in seconds): 6.51\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.18478279296875 - Training Accuracy:= 0.9841200709342957 - Test Accuracy:= 0.9743000268936157\n",
      "Time taken (in seconds): 6.33\n",
      "6 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.8916821875 - Training Accuracy:= 0.9277600646018982 - Test Accuracy:= 0.9340000152587891\n",
      "Time taken (in seconds): 6.34\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.4569765234375 - Training Accuracy:= 0.9539600610733032 - Test Accuracy:= 0.9564000368118286\n",
      "Time taken (in seconds): 6.51\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.3603162890625 - Training Accuracy:= 0.963860034942627 - Test Accuracy:= 0.9635000228881836\n",
      "Time taken (in seconds): 6.45\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.3029531640625 - Training Accuracy:= 0.9699400663375854 - Test Accuracy:= 0.9675000309944153\n",
      "Time taken (in seconds): 6.25\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.26561859375 - Training Accuracy:= 0.9736600518226624 - Test Accuracy:= 0.970300018787384\n",
      "Time taken (in seconds): 6.42\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.23882806640625 - Training Accuracy:= 0.9779800772666931 - Test Accuracy:= 0.9731000661849976\n",
      "Time taken (in seconds): 6.46\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.2178373828125 - Training Accuracy:= 0.9803200364112854 - Test Accuracy:= 0.9752000570297241\n",
      "Time taken (in seconds): 6.41\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.2019346484375 - Training Accuracy:= 0.9803800582885742 - Test Accuracy:= 0.9741000533103943\n",
      "Time taken (in seconds): 6.25\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.18919962890625 - Training Accuracy:= 0.9834000468254089 - Test Accuracy:= 0.976300060749054\n",
      "Time taken (in seconds): 6.50\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.1815345703125 - Training Accuracy:= 0.9833600521087646 - Test Accuracy:= 0.9756000638008118\n",
      "Time taken (in seconds): 6.47\n",
      "7 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.883592265625 - Training Accuracy:= 0.9297800660133362 - Test Accuracy:= 0.9373000264167786\n",
      "Time taken (in seconds): 6.25\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.4392925390625 - Training Accuracy:= 0.9532800912857056 - Test Accuracy:= 0.9562000632286072\n",
      "Time taken (in seconds): 6.40\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.349838515625 - Training Accuracy:= 0.963360071182251 - Test Accuracy:= 0.9637000560760498\n",
      "Time taken (in seconds): 6.49\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.2974933984375 - Training Accuracy:= 0.9702000617980957 - Test Accuracy:= 0.9668000340461731\n",
      "Time taken (in seconds): 6.36\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.261955546875 - Training Accuracy:= 0.9727600812911987 - Test Accuracy:= 0.9687000513076782\n",
      "Time taken (in seconds): 6.32\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.23772484375 - Training Accuracy:= 0.975540041923523 - Test Accuracy:= 0.9700000286102295\n",
      "Time taken (in seconds): 6.45\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.21770630859375 - Training Accuracy:= 0.9783200621604919 - Test Accuracy:= 0.971500039100647\n",
      "Time taken (in seconds): 6.62\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.2021460546875 - Training Accuracy:= 0.979900062084198 - Test Accuracy:= 0.9734000563621521\n",
      "Time taken (in seconds): 6.50\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.1894403515625 - Training Accuracy:= 0.9817600846290588 - Test Accuracy:= 0.9735000729560852\n",
      "Time taken (in seconds): 6.64\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.181831328125 - Training Accuracy:= 0.982740044593811 - Test Accuracy:= 0.9738000631332397\n",
      "Time taken (in seconds): 6.53\n",
      "8 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.87014203125 - Training Accuracy:= 0.9286800622940063 - Test Accuracy:= 0.9349000453948975\n",
      "Time taken (in seconds): 6.34\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.455535 - Training Accuracy:= 0.9529000520706177 - Test Accuracy:= 0.9547000527381897\n",
      "Time taken (in seconds): 6.36\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.359089609375 - Training Accuracy:= 0.9626800417900085 - Test Accuracy:= 0.9633000493049622\n",
      "Time taken (in seconds): 6.48\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.3042429296875 - Training Accuracy:= 0.9688200354576111 - Test Accuracy:= 0.9660000205039978\n",
      "Time taken (in seconds): 6.40\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.2676987109375 - Training Accuracy:= 0.9722200632095337 - Test Accuracy:= 0.9679000377655029\n",
      "Time taken (in seconds): 6.28\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.24177462890625 - Training Accuracy:= 0.976080060005188 - Test Accuracy:= 0.9711000323295593\n",
      "Time taken (in seconds): 6.57\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.221251484375 - Training Accuracy:= 0.9775600433349609 - Test Accuracy:= 0.9722000360488892\n",
      "Time taken (in seconds): 6.49\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.20694505859375 - Training Accuracy:= 0.9789000749588013 - Test Accuracy:= 0.971500039100647\n",
      "Time taken (in seconds): 6.31\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.19403806640625 - Training Accuracy:= 0.9812000393867493 - Test Accuracy:= 0.9729000329971313\n",
      "Time taken (in seconds): 6.30\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.18590509765625 - Training Accuracy:= 0.9821200370788574 - Test Accuracy:= 0.9737000465393066\n",
      "Time taken (in seconds): 6.52\n",
      "9 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.88056578125 - Training Accuracy:= 0.9307400584220886 - Test Accuracy:= 0.9377000331878662\n",
      "Time taken (in seconds): 6.43\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.453006640625 - Training Accuracy:= 0.9528600573539734 - Test Accuracy:= 0.9551000595092773\n",
      "Time taken (in seconds): 6.26\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.3604367578125 - Training Accuracy:= 0.9619600772857666 - Test Accuracy:= 0.9622000455856323\n",
      "Time taken (in seconds): 6.45\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.30427140625 - Training Accuracy:= 0.9682800769805908 - Test Accuracy:= 0.9675000309944153\n",
      "Time taken (in seconds): 6.46\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.26755974609375 - Training Accuracy:= 0.9701000452041626 - Test Accuracy:= 0.9663000702857971\n",
      "Time taken (in seconds): 6.33\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.24092591796875 - Training Accuracy:= 0.9761800765991211 - Test Accuracy:= 0.969700038433075\n",
      "Time taken (in seconds): 6.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epoch = 7 - Training Cross Entropy:= 0.21974119140625 - Training Accuracy:= 0.9783800840377808 - Test Accuracy:= 0.9706000685691833\n",
      "Time taken (in seconds): 6.45\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.2040345703125 - Training Accuracy:= 0.9802200794219971 - Test Accuracy:= 0.972100019454956\n",
      "Time taken (in seconds): 6.42\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.1908826953125 - Training Accuracy:= 0.9817200899124146 - Test Accuracy:= 0.9735000729560852\n",
      "Time taken (in seconds): 6.26\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.182818125 - Training Accuracy:= 0.9833200573921204 - Test Accuracy:= 0.9730000495910645\n",
      "Time taken (in seconds): 6.46\n"
     ]
    }
   ],
   "source": [
    "result_for_ten = []\n",
    "for s in range(10):\n",
    "    print(s,\"!!!!!!!!!!!!!!!!!\")\n",
    "    DROPOUT_RATE = 0\n",
    "    BATCH_SIZE = 200\n",
    "    HIDDEN_SIZE = 128\n",
    "    NUM_EPOCHS = 10\n",
    "    LEARNING_RATE = 0.001\n",
    "    L2_PENLTY = 0.001\n",
    "\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    path = f\"OPT-SELFALG_SEED_{s}-LearnRate_{LEARNING_RATE}-L2_{L2_PENLTY}-TIME_{current_time}\"\n",
    "\n",
    "#     Set log summary\n",
    "\n",
    "    train_log_dir = 'logs/mnist/' + path + '/train'\n",
    "    test_log_dir = 'logs/mnist/' + path + '/test'\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "    test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "\n",
    "    size_input = int(tf.shape(x_train)[1])\n",
    "    size_hidden = HIDDEN_SIZE\n",
    "    size_output = int(tf.shape(y_train)[1])\n",
    "    number_of_train_examples = int(tf.shape(x_train)[0])\n",
    "    number_of_test_examples = int(tf.shape(x_test)[0])\n",
    "\n",
    "\n",
    "    # print(\"size_input\",size_input)\n",
    "    # print(\"size_output\",size_output)\n",
    "    # print(\"number_of_train_examples\",number_of_train_examples)\n",
    "    # print(\"number_of_test_examples\",number_of_test_examples)\n",
    "\n",
    "\n",
    "    mlp_on_gpu = MLP(size_input, size_hidden, size_output, device='cpu')\n",
    "    time_start = time.time()\n",
    "    epoch = 1\n",
    "    loss_diff,last_loss = 1,0\n",
    "\n",
    "    while epoch <= NUM_EPOCHS and abs(loss_diff) > 0.00001:\n",
    "        loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BATCH_SIZE+BATCH_SIZE//4, seed=epoch*(seed)).batch(BATCH_SIZE)\n",
    "        for inputs, outputs in train_ds:\n",
    "            cur_loss, preds = mlp_on_gpu.backward(inputs, outputs, dropout_rate=DROPOUT_RATE, learning_rate=LEARNING_RATE, L2=L2_PENLTY)\n",
    "            loss_total_gpu += cur_loss\n",
    "      # Calculate Accuracy\n",
    "        train_accuracy, test_accuracy = tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.CategoricalAccuracy()\n",
    "        train_accuracy.update_state(y_train, mlp_on_gpu.forward(x_train))\n",
    "        test_accuracy.update_state(y_test, mlp_on_gpu.forward(x_test))\n",
    "        train_loss = np.sum(loss_total_gpu) / x_train.shape[0]\n",
    "        test_loss = np.sum(mlp_on_gpu.loss(mlp_on_gpu.forward(x_test), y_test)) / x_test.shape[0]\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss, step=epoch)\n",
    "            tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss, step=epoch)\n",
    "            tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "        \n",
    "        \n",
    "        loss_diff = train_loss - last_loss\n",
    "        last_loss = train_loss\n",
    "        print(f'Number of Epoch = {epoch} - Training Cross Entropy:= {np.sum(loss_total_gpu) / x_train.shape[0]} - Training Accuracy:= {train_accuracy.result().numpy()} - Test Accuracy:= {test_accuracy.result().numpy()}')\n",
    "        time_taken = time.time() - time_start\n",
    "        print('Time taken (in seconds): {:.2f}'.format(time_taken))\n",
    "        time_start = time.time()\n",
    "        epoch += 1\n",
    "\n",
    "    # record loss and accuracy for final test set:\n",
    "    final_test_loss = np.sum(mlp_on_gpu.loss(mlp_on_gpu.forward(x_final_test), y_final_test)) / x_final_test.shape[0]\n",
    "    final_test_acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "    final_test_acc.update_state(y_final_test, mlp_on_gpu.forward(x_final_test))\n",
    "    result_for_ten.append([final_test_loss,final_test_acc.result().numpy()])\n",
    "#     print(result_for_ten)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b386eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.08820419921875, 0.97310007],\n",
       " [0.09800726318359375, 0.97120005],\n",
       " [0.08741912231445312, 0.9753001],\n",
       " [0.0882435302734375, 0.9718],\n",
       " [0.0872445556640625, 0.9735001],\n",
       " [0.08714856567382813, 0.97410005],\n",
       " [0.08838856201171875, 0.9728],\n",
       " [0.0893430419921875, 0.97330004],\n",
       " [0.08994267578125, 0.97310007],\n",
       " [0.0875046142578125, 0.9717001]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_for_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f96603ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08914461303710938 0.9729900538921357\n"
     ]
    }
   ],
   "source": [
    "print(sum(map(lambda x: x[0], result_for_ten))/len(result_for_ten),\n",
    "      sum(map(lambda x: x[1], result_for_ten))/len(result_for_ten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76761228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
