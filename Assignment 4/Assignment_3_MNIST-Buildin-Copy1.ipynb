{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ad9c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 5693\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "NUM_OF_CATEGORY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f735fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.fashion_mnist\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_final_test, y_final_test = x_test, y_test\n",
    "\n",
    "x_test = x_train[50000:60000]\n",
    "x_train = x_train[0:50000]\n",
    "y_test = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]\n",
    "\n",
    "x_train, x_test, x_final_test = np.reshape(x_train / 255.0, (int(tf.shape(x_train)[0]),-1)), np.reshape(x_test / 255.0, (int(tf.shape(x_test)[0]),-1)), np.reshape(x_final_test / 255.0, (int(tf.shape(x_final_test)[0]),-1))\n",
    "one_hot_y = lambda t: [1 if i == t else 0 for i in range(NUM_OF_CATEGORY)]\n",
    "y_train, y_test, y_final_test = np.array([one_hot_y(y) for y in y_train]), np.array([one_hot_y(y) for y in y_test]), np.array([one_hot_y(y) for y in y_final_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fb30ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self, size_input, size_hidden, size_output, device=None):\n",
    "        super(MLP, self).__init__()\n",
    "        \"\"\"\n",
    "        size_input: int, size of input layer\n",
    "        size_hidden: int, size of hidden layer\n",
    "        size_output: int, size of output layer\n",
    "        device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
    "        \"\"\"\n",
    "        self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
    "        size_input, size_hidden, size_output, device\n",
    "        # Initialize weights between input layer and hidden layer 1\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden], seed=seed, stddev=0.1))\n",
    "        # Initialize biases for hidden layer 1\n",
    "        self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden], seed=seed))\n",
    "         # Initialize weights between hidden layer 1 and hidden layer 2\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.size_hidden, self.size_hidden], seed=seed, stddev=0.1))\n",
    "        # Initialize biases for hidden layer 2\n",
    "        self.b2 = tf.Variable(tf.random.normal([1, self.size_hidden], seed=seed))\n",
    "         # Initialize weights between hidden layer 2 and output layer\n",
    "        self.W3 = tf.Variable(tf.random.normal([self.size_hidden, self.size_output], seed=seed, stddev=0.1))\n",
    "        # Initialize biases for output layer\n",
    "        self.b3 = tf.Variable(tf.random.normal([1, self.size_output], seed=seed))\n",
    "\n",
    "        # Define variables to be updated during backpropagation\n",
    "        self.MLP_variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
    "        # self.MLP_variables = [self.W1, self.W3, self.b1, self.b3]\n",
    "\n",
    "    \n",
    "    def forward(self, X, dropout_rate=0):\n",
    "        \"\"\"\n",
    "        forward pass\n",
    "        X: Tensor, inputs\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
    "                self.y = self.compute_output(X, dropout_rate=dropout_rate)\n",
    "        else:\n",
    "            self.y = self.compute_output(X, dropout_rate=dropout_rate)\n",
    "\n",
    "        return self.y\n",
    "  \n",
    "    def loss(self, y_pred, y_true, L1=0, L2=0):\n",
    "        '''\n",
    "        y_pred - Tensor of shape (batch_size, size_output)\n",
    "        y_true - Tensor of shape (batch_size, size_output)\n",
    "        '''\n",
    "        y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        l2_penlty = (tf.nn.l2_loss(self.W1)+tf.nn.l2_loss(self.W2)+tf.nn.l2_loss(self.W3))*L2\n",
    "        loss_with_l2 = l2_penlty+tf.losses.categorical_crossentropy(y_true_tf, y_pred_tf)\n",
    "#         print(\"y_true_tf\",y_true_tf,\"y_pred_tf\",y_pred_tf)\n",
    "        return loss_with_l2\n",
    "  \n",
    "    def backward(self, X_train, y_train, dropout_rate, learning_rate, L1=0, L2=0):\n",
    "        \"\"\"\n",
    "        backward pass\n",
    "        \"\"\"\n",
    "#         optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(X_train,dropout_rate=dropout_rate)\n",
    "            current_loss = self.loss(predicted, y_train, L2=L2)\n",
    "        grads = tape.gradient(current_loss, self.MLP_variables)\n",
    "        \n",
    "        \n",
    "        optimizer.apply_gradients(zip(grads, self.MLP_variables))\n",
    "        return current_loss, predicted\n",
    "        \n",
    "        \n",
    "    def compute_output(self, X, dropout_rate=0):\n",
    "        \"\"\"\n",
    "        Custom method to obtain output tensor during forward pass\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        X_tf = tf.cast(X, dtype=tf.float32)\n",
    "        #Remember to normalize your dataset before moving forward\n",
    "        # Compute values in hidden layer 1\n",
    "        what = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        hhat = tf.nn.relu(what)\n",
    "\n",
    "        # Compute values in hidden layer 2\n",
    "        what = tf.matmul(hhat, self.W2) + self.b2\n",
    "        hhat = tf.nn.relu(what)\n",
    "\n",
    "        # Compute output\n",
    "        output = tf.matmul(hhat, self.W3) + self.b3\n",
    "        #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
    "        #Second add tf.Softmax(output) and then return this variable\n",
    "        return tf.nn.softmax(output)\n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d563dcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.5322098828125 - Training Accuracy:= 0.9084600806236267 - Test Accuracy:= 0.912600040435791\n",
      "Time taken (in seconds): 4.90\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.234325 - Training Accuracy:= 0.9405200481414795 - Test Accuracy:= 0.9448000192642212\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.17761802734375 - Training Accuracy:= 0.9552600383758545 - Test Accuracy:= 0.9568000435829163\n",
      "Time taken (in seconds): 5.32\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.143123759765625 - Training Accuracy:= 0.963140070438385 - Test Accuracy:= 0.9618000388145447\n",
      "Time taken (in seconds): 5.07\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.12083126953125 - Training Accuracy:= 0.9675800800323486 - Test Accuracy:= 0.964400053024292\n",
      "Time taken (in seconds): 4.90\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.102825244140625 - Training Accuracy:= 0.9733200669288635 - Test Accuracy:= 0.968000054359436\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.089746484375 - Training Accuracy:= 0.9753400683403015 - Test Accuracy:= 0.9683000445365906\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.07905673828125 - Training Accuracy:= 0.9795200824737549 - Test Accuracy:= 0.972100019454956\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.070876337890625 - Training Accuracy:= 0.9789000749588013 - Test Accuracy:= 0.9712000489234924\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.0631575732421875 - Training Accuracy:= 0.982960045337677 - Test Accuracy:= 0.9735000729560852\n",
      "Time taken (in seconds): 4.75\n",
      "1 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.5260667578125 - Training Accuracy:= 0.9117000699043274 - Test Accuracy:= 0.9206000566482544\n",
      "Time taken (in seconds): 4.85\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.22688783203125 - Training Accuracy:= 0.9440600872039795 - Test Accuracy:= 0.9484000205993652\n",
      "Time taken (in seconds): 4.89\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.17043681640625 - Training Accuracy:= 0.9577800631523132 - Test Accuracy:= 0.9613000750541687\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.13696611328125 - Training Accuracy:= 0.9660400748252869 - Test Accuracy:= 0.9643000364303589\n",
      "Time taken (in seconds): 4.82\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.115449619140625 - Training Accuracy:= 0.9689000844955444 - Test Accuracy:= 0.9657000303268433\n",
      "Time taken (in seconds): 4.99\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.0996929296875 - Training Accuracy:= 0.973240077495575 - Test Accuracy:= 0.969200074672699\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.0866953515625 - Training Accuracy:= 0.975640058517456 - Test Accuracy:= 0.968000054359436\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.07758748046875 - Training Accuracy:= 0.9796600937843323 - Test Accuracy:= 0.9694000482559204\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.06898078125 - Training Accuracy:= 0.9792400598526001 - Test Accuracy:= 0.9690000414848328\n",
      "Time taken (in seconds): 4.80\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.061486171875 - Training Accuracy:= 0.9829200506210327 - Test Accuracy:= 0.9718000292778015\n",
      "Time taken (in seconds): 4.74\n",
      "2 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.514661171875 - Training Accuracy:= 0.9147000312805176 - Test Accuracy:= 0.9259000420570374\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.2262293359375 - Training Accuracy:= 0.9460800886154175 - Test Accuracy:= 0.948900043964386\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.1686275390625 - Training Accuracy:= 0.9563800692558289 - Test Accuracy:= 0.9562000632286072\n",
      "Time taken (in seconds): 4.79\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.135312060546875 - Training Accuracy:= 0.96614009141922 - Test Accuracy:= 0.9618000388145447\n",
      "Time taken (in seconds): 4.85\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.11398015625 - Training Accuracy:= 0.9676400423049927 - Test Accuracy:= 0.9629000425338745\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.0979339453125 - Training Accuracy:= 0.9723000526428223 - Test Accuracy:= 0.9648000597953796\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.0848252734375 - Training Accuracy:= 0.9775200486183167 - Test Accuracy:= 0.9695000648498535\n",
      "Time taken (in seconds): 4.79\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.0754510595703125 - Training Accuracy:= 0.9793800711631775 - Test Accuracy:= 0.9686000347137451\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.067163525390625 - Training Accuracy:= 0.9811800718307495 - Test Accuracy:= 0.9699000716209412\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.059282763671875 - Training Accuracy:= 0.9834000468254089 - Test Accuracy:= 0.9717000722885132\n",
      "Time taken (in seconds): 4.78\n",
      "3 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.58793171875 - Training Accuracy:= 0.9129400849342346 - Test Accuracy:= 0.9243000149726868\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.23696357421875 - Training Accuracy:= 0.9411600828170776 - Test Accuracy:= 0.9463000297546387\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.177673671875 - Training Accuracy:= 0.9541600346565247 - Test Accuracy:= 0.9557000398635864\n",
      "Time taken (in seconds): 5.11\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.142736318359375 - Training Accuracy:= 0.9629400372505188 - Test Accuracy:= 0.9611000418663025\n",
      "Time taken (in seconds): 4.80\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.12015076171875 - Training Accuracy:= 0.9662800431251526 - Test Accuracy:= 0.963200032711029\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.102981875 - Training Accuracy:= 0.9718000888824463 - Test Accuracy:= 0.9670000672340393\n",
      "Time taken (in seconds): 4.91\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.08966171875 - Training Accuracy:= 0.9752000570297241 - Test Accuracy:= 0.968500018119812\n",
      "Time taken (in seconds): 5.28\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.07964505859375 - Training Accuracy:= 0.9782000780105591 - Test Accuracy:= 0.969700038433075\n",
      "Time taken (in seconds): 4.80\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.07151013671875 - Training Accuracy:= 0.9788200855255127 - Test Accuracy:= 0.9690000414848328\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.0631006103515625 - Training Accuracy:= 0.9827000498771667 - Test Accuracy:= 0.969700038433075\n",
      "Time taken (in seconds): 4.74\n",
      "4 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.5072648046875 - Training Accuracy:= 0.9125200510025024 - Test Accuracy:= 0.9219000339508057\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.22967359375 - Training Accuracy:= 0.9412800669670105 - Test Accuracy:= 0.9445000290870667\n",
      "Time taken (in seconds): 4.82\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.1729198828125 - Training Accuracy:= 0.9559000730514526 - Test Accuracy:= 0.9568000435829163\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.138366328125 - Training Accuracy:= 0.9643800854682922 - Test Accuracy:= 0.9634000658988953\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.116156796875 - Training Accuracy:= 0.9661800861358643 - Test Accuracy:= 0.9638000726699829\n",
      "Time taken (in seconds): 4.79\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.10007802734375 - Training Accuracy:= 0.9739400744438171 - Test Accuracy:= 0.9682000279426575\n",
      "Time taken (in seconds): 4.86\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.086475234375 - Training Accuracy:= 0.975640058517456 - Test Accuracy:= 0.9694000482559204\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.077005419921875 - Training Accuracy:= 0.9778600931167603 - Test Accuracy:= 0.9700000286102295\n",
      "Time taken (in seconds): 4.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epoch = 9 - Training Cross Entropy:= 0.068595224609375 - Training Accuracy:= 0.9793200492858887 - Test Accuracy:= 0.9702000617980957\n",
      "Time taken (in seconds): 4.82\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.060810146484375 - Training Accuracy:= 0.9833600521087646 - Test Accuracy:= 0.9726000428199768\n",
      "Time taken (in seconds): 4.79\n",
      "5 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.563668828125 - Training Accuracy:= 0.9044400453567505 - Test Accuracy:= 0.9150000214576721\n",
      "Time taken (in seconds): 4.72\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.235524453125 - Training Accuracy:= 0.9419000744819641 - Test Accuracy:= 0.9490000605583191\n",
      "Time taken (in seconds): 4.82\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.17729828125 - Training Accuracy:= 0.9547000527381897 - Test Accuracy:= 0.957800030708313\n",
      "Time taken (in seconds): 4.71\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.14217369140625 - Training Accuracy:= 0.9627200365066528 - Test Accuracy:= 0.9629000425338745\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.11939318359375 - Training Accuracy:= 0.9664400815963745 - Test Accuracy:= 0.964400053024292\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.1021471484375 - Training Accuracy:= 0.9724200367927551 - Test Accuracy:= 0.9687000513076782\n",
      "Time taken (in seconds): 4.72\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.08897416015625 - Training Accuracy:= 0.9755200743675232 - Test Accuracy:= 0.9683000445365906\n",
      "Time taken (in seconds): 4.81\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.0784113525390625 - Training Accuracy:= 0.978920042514801 - Test Accuracy:= 0.971000075340271\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.0700975732421875 - Training Accuracy:= 0.9781400561332703 - Test Accuracy:= 0.969200074672699\n",
      "Time taken (in seconds): 5.00\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.0625371875 - Training Accuracy:= 0.9838000535964966 - Test Accuracy:= 0.9727000594139099\n",
      "Time taken (in seconds): 4.75\n",
      "6 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.51555109375 - Training Accuracy:= 0.9104800820350647 - Test Accuracy:= 0.9190000295639038\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.2311705078125 - Training Accuracy:= 0.9404000639915466 - Test Accuracy:= 0.9438000321388245\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.17257783203125 - Training Accuracy:= 0.9550600647926331 - Test Accuracy:= 0.9552000164985657\n",
      "Time taken (in seconds): 4.74\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.13824330078125 - Training Accuracy:= 0.9648400545120239 - Test Accuracy:= 0.9604000449180603\n",
      "Time taken (in seconds): 4.74\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.11625501953125 - Training Accuracy:= 0.9660800695419312 - Test Accuracy:= 0.9599000215530396\n",
      "Time taken (in seconds): 4.73\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.09950611328125 - Training Accuracy:= 0.9728800654411316 - Test Accuracy:= 0.9652000665664673\n",
      "Time taken (in seconds): 4.78\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.086512880859375 - Training Accuracy:= 0.9743200540542603 - Test Accuracy:= 0.966200053691864\n",
      "Time taken (in seconds): 4.73\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.0760329296875 - Training Accuracy:= 0.9782200455665588 - Test Accuracy:= 0.9677000641822815\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.067946279296875 - Training Accuracy:= 0.978920042514801 - Test Accuracy:= 0.9669000506401062\n",
      "Time taken (in seconds): 4.81\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.06030228515625 - Training Accuracy:= 0.9840400815010071 - Test Accuracy:= 0.9702000617980957\n",
      "Time taken (in seconds): 4.74\n",
      "7 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.5306599609375 - Training Accuracy:= 0.9133000373840332 - Test Accuracy:= 0.9208000302314758\n",
      "Time taken (in seconds): 4.74\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.230225 - Training Accuracy:= 0.9408600330352783 - Test Accuracy:= 0.9431000351905823\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.1728303125 - Training Accuracy:= 0.9562400579452515 - Test Accuracy:= 0.9558000564575195\n",
      "Time taken (in seconds): 4.82\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.13904791015625 - Training Accuracy:= 0.966200053691864 - Test Accuracy:= 0.9628000259399414\n",
      "Time taken (in seconds): 4.85\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.116878515625 - Training Accuracy:= 0.9690200686454773 - Test Accuracy:= 0.9634000658988953\n",
      "Time taken (in seconds): 4.73\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.100923408203125 - Training Accuracy:= 0.9741800427436829 - Test Accuracy:= 0.9677000641822815\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.087666943359375 - Training Accuracy:= 0.9765400886535645 - Test Accuracy:= 0.9684000611305237\n",
      "Time taken (in seconds): 4.81\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.0780172021484375 - Training Accuracy:= 0.9783400893211365 - Test Accuracy:= 0.9678000211715698\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.069602509765625 - Training Accuracy:= 0.980440080165863 - Test Accuracy:= 0.9689000248908997\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.06265814453125 - Training Accuracy:= 0.9833200573921204 - Test Accuracy:= 0.970300018787384\n",
      "Time taken (in seconds): 4.74\n",
      "8 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.513972734375 - Training Accuracy:= 0.8988800644874573 - Test Accuracy:= 0.9111000299453735\n",
      "Time taken (in seconds): 4.74\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.232237421875 - Training Accuracy:= 0.9399600625038147 - Test Accuracy:= 0.9421000480651855\n",
      "Time taken (in seconds): 4.76\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.1745597265625 - Training Accuracy:= 0.9546800851821899 - Test Accuracy:= 0.9554000496864319\n",
      "Time taken (in seconds): 4.65\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.1403482421875 - Training Accuracy:= 0.9634400606155396 - Test Accuracy:= 0.9620000720024109\n",
      "Time taken (in seconds): 4.73\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.11909130859375 - Training Accuracy:= 0.9664600491523743 - Test Accuracy:= 0.96260005235672\n",
      "Time taken (in seconds): 4.67\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.10261142578125 - Training Accuracy:= 0.9705400466918945 - Test Accuracy:= 0.9653000235557556\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 7 - Training Cross Entropy:= 0.09021466796875 - Training Accuracy:= 0.9750600457191467 - Test Accuracy:= 0.96670001745224\n",
      "Time taken (in seconds): 4.86\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.080617724609375 - Training Accuracy:= 0.9758800864219666 - Test Accuracy:= 0.9657000303268433\n",
      "Time taken (in seconds): 4.75\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.072547587890625 - Training Accuracy:= 0.9778400659561157 - Test Accuracy:= 0.9677000641822815\n",
      "Time taken (in seconds): 4.79\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.064575654296875 - Training Accuracy:= 0.9803600907325745 - Test Accuracy:= 0.9686000347137451\n",
      "Time taken (in seconds): 4.81\n",
      "9 !!!!!!!!!!!!!!!!!\n",
      "Number of Epoch = 1 - Training Cross Entropy:= 0.51735125 - Training Accuracy:= 0.9061400890350342 - Test Accuracy:= 0.9146000146865845\n",
      "Time taken (in seconds): 4.80\n",
      "Number of Epoch = 2 - Training Cross Entropy:= 0.23242296875 - Training Accuracy:= 0.942840039730072 - Test Accuracy:= 0.9473000168800354\n",
      "Time taken (in seconds): 4.85\n",
      "Number of Epoch = 3 - Training Cross Entropy:= 0.17342494140625 - Training Accuracy:= 0.9565200805664062 - Test Accuracy:= 0.9582000374794006\n",
      "Time taken (in seconds): 4.82\n",
      "Number of Epoch = 4 - Training Cross Entropy:= 0.139416328125 - Training Accuracy:= 0.9633800387382507 - Test Accuracy:= 0.9620000720024109\n",
      "Time taken (in seconds): 4.85\n",
      "Number of Epoch = 5 - Training Cross Entropy:= 0.115548515625 - Training Accuracy:= 0.9670200347900391 - Test Accuracy:= 0.9629000425338745\n",
      "Time taken (in seconds): 4.85\n",
      "Number of Epoch = 6 - Training Cross Entropy:= 0.0994948046875 - Training Accuracy:= 0.973300039768219 - Test Accuracy:= 0.9664000272750854\n",
      "Time taken (in seconds): 4.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epoch = 7 - Training Cross Entropy:= 0.08547451171875 - Training Accuracy:= 0.9753800630569458 - Test Accuracy:= 0.9679000377655029\n",
      "Time taken (in seconds): 4.77\n",
      "Number of Epoch = 8 - Training Cross Entropy:= 0.0759436279296875 - Training Accuracy:= 0.9783000349998474 - Test Accuracy:= 0.968500018119812\n",
      "Time taken (in seconds): 5.24\n",
      "Number of Epoch = 9 - Training Cross Entropy:= 0.06696216796875 - Training Accuracy:= 0.9803600907325745 - Test Accuracy:= 0.9682000279426575\n",
      "Time taken (in seconds): 4.92\n",
      "Number of Epoch = 10 - Training Cross Entropy:= 0.0596779736328125 - Training Accuracy:= 0.9833400845527649 - Test Accuracy:= 0.9709000587463379\n",
      "Time taken (in seconds): 4.83\n"
     ]
    }
   ],
   "source": [
    "result_for_ten = []\n",
    "for s in range(10):\n",
    "    print(s,\"!!!!!!!!!!!!!!!!!\")\n",
    "    DROPOUT_RATE = 0\n",
    "    BATCH_SIZE = 200\n",
    "    HIDDEN_SIZE = 128\n",
    "    NUM_EPOCHS = 10\n",
    "    LEARNING_RATE = 0.001\n",
    "    L2_PENLTY = 0\n",
    "\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    path = f\"OPT-Adam_SEED_{s}-LearnRate_{LEARNING_RATE}-L2_{L2_PENLTY}-TIME_{current_time}\"\n",
    "\n",
    "#     Set log summary\n",
    "\n",
    "    train_log_dir = 'logs/mnist/' + path + '/train'\n",
    "    test_log_dir = 'logs/mnist/' + path + '/test'\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "    test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "\n",
    "    size_input = int(tf.shape(x_train)[1])\n",
    "    size_hidden = HIDDEN_SIZE\n",
    "    size_output = int(tf.shape(y_train)[1])\n",
    "    number_of_train_examples = int(tf.shape(x_train)[0])\n",
    "    number_of_test_examples = int(tf.shape(x_test)[0])\n",
    "\n",
    "\n",
    "    # print(\"size_input\",size_input)\n",
    "    # print(\"size_output\",size_output)\n",
    "    # print(\"number_of_train_examples\",number_of_train_examples)\n",
    "    # print(\"number_of_test_examples\",number_of_test_examples)\n",
    "\n",
    "\n",
    "    mlp_on_gpu = MLP(size_input, size_hidden, size_output, device='cpu')\n",
    "    time_start = time.time()\n",
    "    epoch = 1\n",
    "    loss_diff,last_loss = 1,0\n",
    "\n",
    "    while epoch <= NUM_EPOCHS and abs(loss_diff) > 0.00001:\n",
    "        loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BATCH_SIZE+BATCH_SIZE//4, seed=epoch*(seed)).batch(BATCH_SIZE)\n",
    "        for inputs, outputs in train_ds:\n",
    "            cur_loss, preds = mlp_on_gpu.backward(inputs, outputs, dropout_rate=DROPOUT_RATE, learning_rate=LEARNING_RATE, L2=L2_PENLTY)\n",
    "            loss_total_gpu += cur_loss\n",
    "      # Calculate Accuracy\n",
    "        train_accuracy, test_accuracy = tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.CategoricalAccuracy()\n",
    "        train_accuracy.update_state(y_train, mlp_on_gpu.forward(x_train))\n",
    "        test_accuracy.update_state(y_test, mlp_on_gpu.forward(x_test))\n",
    "        train_loss = np.sum(loss_total_gpu) / x_train.shape[0]\n",
    "        test_loss = np.sum(mlp_on_gpu.loss(mlp_on_gpu.forward(x_test), y_test)) / x_test.shape[0]\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss, step=epoch)\n",
    "            tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', test_loss, step=epoch)\n",
    "            tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "        \n",
    "        \n",
    "        loss_diff = train_loss - last_loss\n",
    "        last_loss = train_loss\n",
    "        print(f'Number of Epoch = {epoch} - Training Cross Entropy:= {np.sum(loss_total_gpu) / x_train.shape[0]} - Training Accuracy:= {train_accuracy.result().numpy()} - Test Accuracy:= {test_accuracy.result().numpy()}')\n",
    "        time_taken = time.time() - time_start\n",
    "        print('Time taken (in seconds): {:.2f}'.format(time_taken))\n",
    "        time_start = time.time()\n",
    "        epoch += 1\n",
    "\n",
    "    # record loss and accuracy for final test set:\n",
    "    final_test_loss = np.sum(mlp_on_gpu.loss(mlp_on_gpu.forward(x_final_test), y_final_test)) / x_final_test.shape[0]\n",
    "    final_test_acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "    final_test_acc.update_state(y_final_test, mlp_on_gpu.forward(x_final_test))\n",
    "    result_for_ten.append([final_test_loss,final_test_acc.result().numpy()])\n",
    "#     print(result_for_ten)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "584cdecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.09765180053710938, 0.96970004],\n",
       " [0.0961176513671875, 0.96830004],\n",
       " [0.09532408447265625, 0.97120005],\n",
       " [0.09724625244140625, 0.9703],\n",
       " [0.0962802978515625, 0.9692001],\n",
       " [0.09398307495117188, 0.9710001],\n",
       " [0.099090234375, 0.9696],\n",
       " [0.09253653564453125, 0.9692001],\n",
       " [0.10103370361328125, 0.9689],\n",
       " [0.09880753784179687, 0.96880007]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_for_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b386eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09680711730957031 0.9696200489997864\n"
     ]
    }
   ],
   "source": [
    "print(sum(map(lambda x: x[0], result_for_ten))/len(result_for_ten),\n",
    "      sum(map(lambda x: x[1], result_for_ten))/len(result_for_ten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd79d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
